Flow
====

The flow components of *python-weka-wrapper* are not related to Weka's KnowledgeFlow. Instead, they were
inspired by the `ADAMS workflow engine <https://adams.cms.waikato.ac.nz/>`_. It is a very simple workflow,
aimed at automating tasks and being easy to extends as well. Instead of linking operators with explicit
connections, this flow uses a tree structure for implicitly defining how the data is processed.

Overview
--------

A workflow component is called an *actor*. All actors are derived from the `Actor` class,
but there are four different kinds of actors present:

 * **source** actors generate data, but don't consume any
 * **transformer** actors consume and generate data, similar to a filter
 * **sink** actors only consume data, e.g., displaying data
 * **control** actors define how the data is passed around in a flow

Data itself is being passed around in *Token* containers.

Due to the limitation of the tree structure of providing only 1-to-n connections, objects can be stored
internally in a flow using a simple dictionary. Special actors store, retrieve, update and delete these
objects.

Life cycle
----------

The typical life-cycle of a flow (actually any actor) can be described through the following method calls:

 # **setup()** configures and checks the flow (outputs error message if failed, None otherwise)
 # **execute()** performs the execution of actors (outputs error message if failed, None otherwise)
 # **wrapup()** finishes up the execution
 # **cleanup()** destructive, frees up memory

Sources
-------

The following *source* actors are available:

 * **FileSupplier** outputs predefined file names
 * **ForLoop** outputs integer tokens as defined by the loop setup (min, max, step)
 * **GetStorageValue** outputs a storage from internal storage
 * **ListFiles** lists files/directories
 * **LoadDatabase** loads data from a database using an SQL query
 * **Start** dummy source that just triggers the execution of other actors following

Transformers
------------

The following *transformers* are available:

 * **ClassSelector** sets/unsets the class attribute of a dataset
 * **CrossValidate** performs cross-validation on a classifier or clusterer
 * **DeleteFile** deletes files that match a regular expression
 * **DeleteStorageValue** deletes a value from internal storage
 * **EvaluationSummary** generates a summary from a classifier's Evaluation object
 * **Filter** applies a Weka filter to the data passing through
 * **InitStorageValue** sets the initial value for a internal storage value
 * **LoadDataset** loads the data stored in the file received as input, either using automatic
   determined loader or user-specified one
 * **MathExpression** computes a numeric value from a expression and numeric input
 * **PassThrough** is a dummy that just passes through the tokens
 * **SetStorageValue** stores the payload of the current token in internal storage
 * **Train** builds a classifier/clusterer/associator and passes on a ModelContainer
 * **UpdateStorageValue** applies an expression to update an internal storage value, e.g.
   incrementing a counter

 Sinks
 -----

 The following *sinks* are available:

  * **ClassifierErrors** displays the classifier errors obtained from an Evaluation object
  * **Console** just outputs a string representation of the object on stdout
  * **DumpFile** similar to *Console*, but stores the string representation in a file
  * **MatrixPlot** displays an Instances object as matrix plot
  * **ModelWriter** stores a trained model on disk
  * **Null** simply swallows any token (like `/dev/null` on Linux)
  * **PRC** plots a precision-recall curve from an Evaluation object
  * **ROC** plots a receiver-operator curver from an Evaluation object

 Control actors
 --------------

 The following *control* actors define how data is getting passed around in a workflow:

  * **Branch** forwards the same input token to all of its sub-branches
  * **ContainerValuePicker** extracts a named value from a container, e.g. the `Model` from a `ModelContainer`
  * **Flow** the outermost actor that also handles the internal storage
  * **Sequence** executes its sub-actors sequentially, with the data generated by the previous being the input
    for the next one
  * **Tee** allows to *tee* off the current token and process it separately in a sub-flow before continuing with
    the processing; optional condition available that determines when a token gets tee'd off
  * **Trigger** executes its sub-actors whenever a token passes through (i.e., when the condition evaluates to True)

Examples
--------

Check out the examples available through the *python-weka-wrapper-examples* project on Github:

  https://github.com/fracpete/python-weka-wrapper-examples

The example scripts are located in the `src/wekaexamples/flow` sub-directory.
